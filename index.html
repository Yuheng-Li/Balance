<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Removing Distributional Discrepancies in Captions Improves Image-Text Alignment.">
  <meta name="keywords" content="Image Generation, Diffusion, Grounding">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Removing Distributional Discrepancies in Captions Improves Image-Text Alignment.</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="icon" href="./static/images/icon.png">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  </head>
  <body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h2 class="title is-2 publication-title">Removing Distributional Discrepancies in Captions Improves Image-Text Alignment</h2>
          <div class="is-size-5">
            <span class="author-block">
                <a href="https://yuheng-li.github.io/" style="color:#f68946;font-weight:normal;">Yuheng Li</a>,                
            </span>
            <span class="author-block">
              <a href="https://hliu.cc/" style="color:#f68946;font-weight:normal;">Haotian Liu</a>,
            </span>
            <span class="author-block">
              <a href="https://pages.cs.wisc.edu/~mucai/" style="color:#f68946;font-weight:normal;">Cai Mu</a>,
            </span>   
            <span class="author-block">
              <a href="https://research.adobe.com/person/yijun-li/" style="color:#468af6;font-weight:normal;">Yijun Li</a>,
            </span>   
            <span class="author-block">
              <a href="https://research.adobe.com/person/eli-shechtman/" style="color:#468af6;font-weight:normal;">Eli Shechtman</a>,
            </span>   
            <span class="author-block">
              <a href="https://research.adobe.com/person/zhe-lin/" style="color:#468af6;font-weight:normal;">Zhe Lin</a>,
            </span>   
            <span class="author-block">
              <a href="https://pages.cs.wisc.edu/~yongjaelee/" style="color:#f68946;font-weight:normal;">Yong Jae Lee</a>,
            </span>   
            <span class="author-block">
              <a href="https://research.adobe.com/person/krishna-kumar-singh/" style="color:#468af6;font-weight:normal;">Krishna Kumar Singh</a>,
            </span>                                  
          </div>

          <br>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><b style="color:#f68946; font-weight:normal">&#x25B6 </b> University of Wisconsin-Madison</b></span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><b style="color:#468af6; font-weight:normal">&#x25B6 </b> Adobe Research</b></span>
          </div>


          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="#" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="#" target="_blank" 
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>

            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img id="teaser" width="150%" src="images/concept.png">
      <!-- <h2 class="subtitle has-text-centered">
        <p style="font-family:Times New Roman"><b>Figure 1. GLIGEN enables versatile grounding capabilities for a frozen text-to-image generation model.</b></p>
      </h2> -->
    </div>
  </div>
</section>


<section class="section"   style="background-color:#efeff081">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In this paper, we introduce a model designed to improve the prediction of image-text alignment, targeting the challenge of compositional understanding in current visual-language models. Our approach focuses on generating high-quality training datasets for the alignment task by producing mixed-type negative captions derived from positive ones. Critically, we address the distribution imbalance between positive and negative captions to ensure that the alignment model does not depend solely on textual information but also considers the associated images for predicting alignment accurately. By creating this enhanced training data, we fine-tune an existing leading visual-language model to boost its capability in understanding alignment. Our model significantly outperforms current top-performing methods across various datasets. We also demonstrate the applicability of our model by ranking the images generated by text-to-image models based on text alignment. 
          </p>
        </div>
      </div>
    </div>
</section>





<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-five-fifths">
        <h2 class="title is-3">
          <img id="painting_icon" width="5%" src="https://cdn-icons-png.flaticon.com/512/3515/3515174.png"> Text Distributional Gap 
        </h2> 
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <div class="content has-text-justified">
          <p>
            The most common approach for training image-text alignment models involves creating hard-negative captions. However, we discovered that hard-negative captions generated by LLMs (e.g., GPT) can lead to distributional biases. For instance, when applied to COCO captions, GPT often replaces "airplane" with "boat" or "giraffe" with "elephant." This makes the text information alone distinguishable within the image-text pair dataset, potentially causing the alignment model to fail in learning true alignment information.
          </p>
        </div>        
        <img id="model" width="90%" src="images/distribution_gap.png">
      </div>
    </div>
  </div>
</section>





<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-five-fifths">
        <h2 class="title is-3"><img id="painting_icon" width="5%" src="https://cdn-icons-png.flaticon.com/512/5379/5379860.png"> Approach </h2> 
      </div>
    </div>

        <div class="columns is-centered has-text-centered">
          <div class="column is-six-fifths">
            <div class="content has-text-justified">
              <ul>
                <li>Use 'swap' and 'replace' strategies to create hard-negative captions.</li>
                <li>Employ a text-only classifier to identify and remove easy positive and negative captions (those that can be distinguished solely by text information). </li>
                <li>Fine-tune a vision-language model (e.g., LLaVA) to enhance image-text alignment capabilities.</li>
              </ul>
            </div>        
            <img id="model" width="90%" src="images/approach.png">
        </div>
  </div>
</section>





<!-- <section class="section">
  <div class="columns is-centered has-text-centered">
    <div class="column is-six-fifths">
      <h2 class="title is-3"><img id="painting_icon" width="3%" src="https://cdn-icons-png.flaticon.com/512/3515/3515174.png"> Results & Applications</h2>
    </div>
  </div> 
<div class="container is-max-desktop">



  <div class="columns is-centered">
    <div class="column is-full-width">
      <h2 class="title is-4"><font color="#000000">Location Control</font></h2>
      <img id="teaser" width="95%" src="images/application0.png">
      <h1>
        <p style="font-family:Times New Roman"><b>PACGen offers the flexibility to effortlessly place your unique object at any desired location. The four distinct color-coded boxes on the left correspond to four resulting images on the right.</b>
      </h1>                 
    </div>
  </div>

  <br>
  <br>


  <div class="columns is-centered">
    <div class="column is-full-width">
      <h2 class="title is-4"><font color="#000000">Image Composition</font></h2>
      <img id="teaser" width="95%" src="images/application1.png">
      <h1>
        <p style="font-family:Times New Roman"><b>PACGen is designed to accommodate multiple objects location control, including both user-provided unique objects and common objects. This capability demonstrates its remarkable potential for addressing image composition challenges..</b>
      </h1>                 
    </div>
  </div>


  <br>
  <br>



  <div class="columns is-centered">
    <div class="column is-full-width">
      <h2 class="title is-4"><font color="#000000">Art Style</font></h2>
      <img id="teaser" width="95%" src="images/application2.png">
      <h1>
        <p style="font-family:Times New Roman"><b>With PACGen, you can effortlessly incorporate your favorite objects and pets into any location and adapt a variety of art styles to create personalized, aesthetically appealing images..</b>
      </h1>                 
    </div>
  </div>

  <br>
  <br>



  <div class="columns is-centered">
    <div class="column is-full-width">
      <h2 class="title is-4"><font color="#000000">Accessorization</font></h2>
      <img id="teaser" width="95%" src="images/application3.png">
      <h1>
        <p style="font-family:Times New Roman"><b>PACGen not only grants you full control over your object's location but also offers the ability to add various accessories or outfits, enabling endless customization possibilities..</b>
      </h1>                 
    </div>
  </div>


  <br>
  <br>



  <div class="columns is-centered">
    <div class="column is-full-width">
      <h2 class="title is-4"><font color="#000000">Attribute</font></h2>
      <img id="teaser" width="95%" src="images/application4.png">
      <h1>
        <p style="font-family:Times New Roman"><b>Additionally, PACGen allows you to modify object attributes, such as color, while still maintaining the control over object location, enhancing the overall customization experience. </b>
      </h1>                 
    </div>
  </div>

  <br>
  <br>



  <div class="columns is-centered">
    <div class="column is-full-width">
      <h2 class="title is-4"><font color="#000000">Hybrid</font></h2>
      <img id="teaser" width="95%" src="images/application5.png">
      <h1>
        <p style="font-family:Times New Roman"><b>We also showcase how PACGen enables you to create a hybrid between your object and other common objects, sparking your imagination and inspiring unique designs..</b>
      </h1>                 
    </div>
  </div>

  <br>
  <br> -->





<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX TODO</h2>
    <pre><code>
@article{li2023pacgen,
  author      = {Li, Yuheng and Liu, Haotian and Wen, Yangming and Lee, Yong Jae},
  title       = {Generate Anything Anywhere in Any Scene},
  publisher   = {arXiv:2306.17154},
  year        = {2023},
}
</code></pre>
  </div>
</section>

<section class="section" id="Acknowledgement">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgement</h2>
    <p>
      This website is adapted from <a
      href="https://gligen.github.io/">GLIGEN</a> , licensed under a <a rel="license"
                                          href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
      Commons Attribution-ShareAlike 4.0 International License</a>.
    </p>
    <p>

    <!-- <a href='https://github.com/Computer-Vision-in-the-Wild/'><img id="painting_icon" width="10%" src="https://avatars.githubusercontent.com/u/97258247?s=200&v=4"> 
    </a> 
    <b> Related Links</b> : 
    <div class="content has-text-justified">
      <ul>
        <li><a href='https://github.com/Computer-Vision-in-the-Wild/'>[Computer Vision in the Wild] </a> </li>
        <li>GLIGEN: (box, concept) &#8594 image || GLIP : image &#8594 (box, concept); See grounded image understanding in <a href='https://github.com/microsoft/GLIP'>[GLIP]</a></li>
        <li>Modulated design and training of foundation models for image understanding <a href='https://react-vl.github.io/'>[REACT]</a></li>
      </ul>
 
    </div>      -->

    
    </p>
  </div>
</section>


</body>
</html>
